<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>AlCalorieApp â€” System Architecture (Mermaid)</title>
    <style>
      :root {
        color-scheme: light;
        --bg: #ffffff;
        --card: #f8f9fa;
        --text: #1a1a1a;
        --muted: #6b7280;
        --border: #d1d5db;
      }
      body {
        margin: 0;
        font-family: ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial, "Apple Color Emoji",
          "Segoe UI Emoji";
        background: var(--bg);
        color: var(--text);
      }
      header {
        padding: 28px 20px 12px;
        max-width: 1400px;
        margin: 0 auto;
        border-bottom: 2px solid var(--border);
      }
      h1 {
        margin: 0;
        font-size: 24px;
        letter-spacing: 0.2px;
        color: #111827;
      }
      p {
        margin: 8px 0 0;
        color: var(--muted);
        line-height: 1.6;
        font-size: 14px;
      }
      .wrap {
        max-width: 1400px;
        margin: 0 auto;
        padding: 24px 20px 40px;
      }
      .card {
        background: var(--card);
        border: 1px solid var(--border);
        border-radius: 12px;
        padding: 24px;
        overflow: auto;
      }
      .hint {
        margin-top: 16px;
        font-size: 13px;
        color: var(--muted);
      }
      code {
        background: #e5e7eb;
        padding: 2px 6px;
        border-radius: 4px;
      }
    </style>
  </head>
  <body>
    <header>
      <h1>AlCalorieApp â€” Total System Architecture</h1>
      <p>
        <b>8-Block Multi-Modal System:</b> Image, Text, and Audio inputs â†’ Preprocessing â†’ Encoder (ViT-L/14) â†’ 
        Decoder (GPT-2/ASR) â†’ RAG + Groq LLaMA-3 Nutrition Estimation â†’ PostgreSQL Tracking â†’ 
        Visualization & AI Advice â†’ PDF Export & Download
      </p>
    </header>

    <div class="wrap">
      <div class="card">
        <pre class="mermaid">
%%{init: {'theme':'base', 'themeVariables': { 'primaryColor':'#dbeafe','primaryTextColor':'#1e3a8a','primaryBorderColor':'#3b82f6','lineColor':'#3b82f6','secondaryColor':'#e0f2fe','tertiaryColor':'#fef3c7'}}}%%
flowchart TB
  START(["START<br/>User Opens App"]) --> BLOCK1

  %% ========================================
  %% BLOCK 1: INPUT LAYER
  %% ========================================
  subgraph BLOCK1["BLOCK 1: INPUT LAYER"]
    direction TB
    INPUT1["Food Image<br/>JPG/PNG<br/>Resolution: Variable"]
    INPUT2["Text Input<br/>Typed Description<br/>Natural Language"]
    INPUT3["Audio Input<br/>Voice Recording<br/>WAV/MP3 Format"]
  end

  BLOCK1 --> BLOCK2

  %% ========================================
  %% BLOCK 2: PREPROCESSING
  %% ========================================
  subgraph BLOCK2["BLOCK 2: PREPROCESSING"]
    direction TB
    PREP1["Image Preprocessing<br/>â€¢ Resize 224x224<br/>â€¢ RGB Conversion<br/>â€¢ Tensor Transform"]
    PREP2["Text Preprocessing<br/>â€¢ Token Normalization<br/>â€¢ Spell Correction<br/>â€¢ POS Tagging"]
    PREP3["Audio Preprocessing<br/>â€¢ Sample Rate Normalization<br/>â€¢ Mono Conversion<br/>â€¢ Denoise + Trim Silence"]
  end

  BLOCK2 --> BLOCK3

  %% ========================================
  %% BLOCK 3: ENCODER
  %% ========================================
  subgraph BLOCK3["BLOCK 3: ENCODER"]
    direction TB
    subgraph ENC1_SUB["Vision Encoder - ViT-L/14"]
      direction TB
      E1_1["Patch Embedding Layer<br/>Image â†’ 16x16 Patches"]
      E1_2["Position Embedding<br/>Spatial Information"]
      E1_3["Transformer Blocks x24<br/>Multi-Head Self-Attention"]
      E1_4["Hidden Layer: 1024 dims<br/>Layer Normalization"]
      E1_5["Visual Feature Vector<br/>Output: 1024-d"]
      E1_1 --> E1_2 --> E1_3 --> E1_4 --> E1_5
    end
    
    subgraph ENC2_SUB["Text Encoder"]
      direction TB
      E2_1["Tokenization Layer<br/>WordPiece/BPE"]
      E2_2["Embedding Layer<br/>Token â†’ Vector"]
      E2_3["Hidden Layer: 768 dims<br/>Contextual Embeddings"]
      E2_1 --> E2_2 --> E2_3
    end
    
    subgraph ENC3_SUB["Audio Encoder - Whisper ASR"]
      direction TB
      E3_1["Mel Spectrogram<br/>Audio â†’ Frequency Features"]
      E3_2["Conv Layers x2<br/>Feature Extraction"]
      E3_3["Transformer Encoder<br/>Self-Attention Layers"]
      E3_4["Hidden Layer: 512 dims<br/>Audio Context Vector"]
      E3_5["Text Transcription Output"]
      E3_1 --> E3_2 --> E3_3 --> E3_4 --> E3_5
    end
  end

  BLOCK3 --> BLOCK4

  %% ========================================
  %% BLOCK 4: DECODER
  %% ========================================
  subgraph BLOCK4["BLOCK 4: DECODER"]
    direction TB
    subgraph DEC1_SUB["BLIP-2 GPT-2 Decoder - Image Path"]
      direction TB
      D1_1["Cross-Attention Layer<br/>Visual Features â†’ Text"]
      D1_2["Transformer Decoder x12<br/>Causal Self-Attention"]
      D1_3["Hidden Layer: 768 dims<br/>Language Model States"]
      D1_4["Feed-Forward Network<br/>2048 â†’ 768 dims"]
      D1_5["Output Layer<br/>Vocabulary Projection"]
      D1_6["Caption Generation<br/>Food Description Text"]
      D1_1 --> D1_2 --> D1_3 --> D1_4 --> D1_5 --> D1_6
    end
    
    subgraph DEC2_SUB["Text Path - Direct"]
      direction TB
      D2_1["Cleaned Text<br/>Preprocessed Input"]
      D2_2["Food Description<br/>Ready for Fusion"]
      D2_1 --> D2_2
    end
    
    subgraph DEC3_SUB["Audio Path - ASR Output"]
      direction TB
      D3_1["Transcribed Text<br/>Speech â†’ Text"]
      D3_2["Post-Processing<br/>Grammar + Context"]
      D3_3["Food Description<br/>From Audio"]
      D3_1 --> D3_2 --> D3_3
    end
    
    MERGE["LangChain Prompt Merger<br/>Context Fusion Layer<br/>Combined Food Description"]
    D1_6 --> MERGE
    D2_2 --> MERGE
    D3_3 --> MERGE
  end

  BLOCK4 --> BLOCK5

  %% ========================================
  %% BLOCK 5: RAG + LLM NUTRITION ESTIMATION
  %% ========================================
  subgraph BLOCK5["BLOCK 5: NUTRITION ESTIMATION"]
    direction TB
    RAG["RAG System<br/>Vector Store: FAISS/Chroma<br/>Nutrition Database Retrieval"]
    LLM["Groq LLaMA-3 8B<br/>LLM Inference"]
    JSON["Nutrition JSON Output<br/>â€¢ Calories<br/>â€¢ Protein/Carbs/Fat<br/>â€¢ Micronutrients"]
    RAG --> LLM --> JSON
  end

  BLOCK5 --> BLOCK6

  %% ========================================
  %% BLOCK 6: STORAGE + TRACKING
  %% ========================================
  subgraph BLOCK6["BLOCK 6: STORAGE & TRACKING"]
    direction TB
    DB[("PostgreSQL Database<br/>â€¢ Food Logs<br/>â€¢ User Profiles<br/>â€¢ Daily Totals")]
    GOALS["User Goals Comparison<br/>â€¢ Calorie Targets<br/>â€¢ Macro Goals<br/>â€¢ Progress Tracking"]
    DB --> GOALS
  end

  BLOCK6 --> BLOCK7

  %% ========================================
  %% BLOCK 7: VISUALIZATION + ADVICE
  %% ========================================
  subgraph BLOCK7["BLOCK 7: VISUALIZATION & ADVICE"]
    direction TB
    VIZ["Data Visualization<br/>Matplotlib/Plotly<br/>â€¢ Calorie Charts<br/>â€¢ Macro Pie Charts"]
    ADVICE["AI Advice Engine<br/>LangChain + LLaMA<br/>â€¢ Gap Analysis<br/>â€¢ Personalized Suggestions"]
    VIZ -.-> ADVICE
  end

  BLOCK7 --> BLOCK8

  %% ========================================
  %% BLOCK 8: OUTPUT & DELIVERY
  %% ========================================
  subgraph BLOCK8["BLOCK 8: OUTPUT & DELIVERY"]
    direction TB
    PDF["PDF Report Generator<br/>FPDF/ReportLab<br/>â€¢ Food Logs<br/>â€¢ Charts<br/>â€¢ Advice"]
    DOWNLOAD["Download Options<br/>ðŸ’¾ Save Locally<br/>ðŸ“§ Email<br/>â˜ï¸ Cloud Storage"]
    PDF --> DOWNLOAD
  end

  BLOCK8 --> END

  END(["END<br/>User Receives Report"])

  %% STYLING
  classDef inputStyle fill:#dbeafe,stroke:#3b82f6,stroke-width:2px,color:#1e3a8a
  classDef processStyle fill:#dcfce7,stroke:#22c55e,stroke-width:2px,color:#166534
  classDef encoderStyle fill:#fef3c7,stroke:#f59e0b,stroke-width:2px,color:#92400e
  classDef decoderStyle fill:#fed7aa,stroke:#ea580c,stroke-width:2px,color:#7c2d12
  classDef llmStyle fill:#e9d5ff,stroke:#a855f7,stroke-width:2px,color:#6b21a8
  classDef storageStyle fill:#e0e7ff,stroke:#6366f1,stroke-width:2px,color:#3730a3
  classDef vizStyle fill:#fce7f3,stroke:#ec4899,stroke-width:2px,color:#9f1239
  classDef outputStyle fill:#d1fae5,stroke:#10b981,stroke-width:2px,color:#065f46

  class BLOCK1 inputStyle
  class BLOCK2 processStyle
  class BLOCK3 encoderStyle
  class BLOCK4 decoderStyle
  class BLOCK5 llmStyle
  class BLOCK6 storageStyle
  class BLOCK7 vizStyle
  class BLOCK8 outputStyle
        </pre>
      </div>

      <div class="hint">
        <strong>Architecture Overview:</strong> This diagram shows the complete system divided into 8 functional blocks, 
        with detailed Encoder (Block 3) and Decoder (Block 4) stages including hidden layers, attention mechanisms, 
        and neural network architecture details. Open this file in any modern browser to view the interactive flowchart. 
        Each block is color-coded for easy identification.
      </div>
    </div>

    <script type="module">
      import mermaid from "https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs";
      mermaid.initialize({
        startOnLoad: true,
        theme: "default",
        flowchart: { 
          curve: "linear",
          padding: 20
        },
        securityLevel: "loose",
      });
    </script>
  </body>
</html>


