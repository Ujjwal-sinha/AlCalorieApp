<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>AlCalorieApp — System Architecture (Mermaid)</title>
    <style>
      :root {
        color-scheme: light;
        --bg: #ffffff;
        --card: #f8f9fa;
        --text: #1a1a1a;
        --muted: #6b7280;
        --border: #d1d5db;
      }
      body {
        margin: 0;
        font-family: ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial, "Apple Color Emoji",
          "Segoe UI Emoji";
        background: var(--bg);
        color: var(--text);
      }
      header {
        padding: 28px 20px 12px;
        max-width: 1400px;
        margin: 0 auto;
        border-bottom: 2px solid var(--border);
      }
      h1 {
        margin: 0;
        font-size: 24px;
        letter-spacing: 0.2px;
        color: #111827;
      }
      p {
        margin: 8px 0 0;
        color: var(--muted);
        line-height: 1.6;
        font-size: 14px;
      }
      .wrap {
        max-width: 1400px;
        margin: 0 auto;
        padding: 24px 20px 40px;
      }
      .card {
        background: var(--card);
        border: 1px solid var(--border);
        border-radius: 12px;
        padding: 24px;
        overflow: auto;
      }
      .hint {
        margin-top: 16px;
        font-size: 13px;
        color: var(--muted);
      }
      code {
        background: #e5e7eb;
        padding: 2px 6px;
        border-radius: 4px;
      }
    </style>
  </head>
  <body>
    <header>
      <h1>AlCalorieApp — Total System Architecture</h1>
      <p>
        <b>8-Block Multi-Modal System:</b> Image, Text, and Audio inputs → Preprocessing → Encoder (ViT-L/14) → 
        Decoder (GPT-2/ASR) → RAG + Groq LLaMA-3 Nutrition Estimation → PostgreSQL Tracking → 
        Visualization & AI Advice → PDF Export & Download
      </p>
    </header>

    <div class="wrap">
      <div class="card">
        <pre class="mermaid">
%%{init: {'theme':'base', 'themeVariables': { 'primaryColor':'#dbeafe','primaryTextColor':'#1e3a8a','primaryBorderColor':'#3b82f6','lineColor':'#3b82f6','secondaryColor':'#e0f2fe','tertiaryColor':'#fef3c7'}}}%%
flowchart TB
  START(["START<br/>User Opens App"]) --> BLOCK1

  %% ========================================
  %% BLOCK 1: INPUT LAYER
  %% ========================================
  subgraph BLOCK1["BLOCK 1: INPUT LAYER"]
    direction TB
    INPUT1["Food Image<br/>JPG/PNG<br/>Resolution: Variable"]
    INPUT2["Text Input<br/>Typed Description<br/>Natural Language"]
    INPUT3["Audio Input<br/>Voice Recording<br/>WAV/MP3 Format"]
  end

  BLOCK1 --> BLOCK2

  %% ========================================
  %% BLOCK 2: PREPROCESSING
  %% ========================================
  subgraph BLOCK2["BLOCK 2: PREPROCESSING"]
    direction TB
    PREP1["Image Preprocessing<br/>• Resize 224x224<br/>• RGB Conversion<br/>• Tensor Transform"]
    PREP2["Text Preprocessing<br/>• Token Normalization<br/>• Spell Correction<br/>• POS Tagging"]
    PREP3["Audio Preprocessing<br/>• Sample Rate Normalization<br/>• Mono Conversion<br/>• Denoise + Trim Silence"]
  end

  BLOCK2 --> BLOCK3

  %% ========================================
  %% BLOCK 3: ENCODER
  %% ========================================
  subgraph BLOCK3["BLOCK 3: ENCODER"]
    direction TB
    subgraph ENC1_SUB["Vision Encoder - ViT-L/14"]
      direction TB
      E1_1["Patch Embedding Layer<br/>Image → 16x16 Patches"]
      E1_2["Position Embedding<br/>Spatial Information"]
      E1_3["Transformer Blocks x24<br/>Multi-Head Self-Attention"]
      E1_4["Hidden Layer: 1024 dims<br/>Layer Normalization"]
      E1_5["Visual Feature Vector<br/>Output: 1024-d"]
      E1_1 --> E1_2 --> E1_3 --> E1_4 --> E1_5
    end
    
    subgraph ENC2_SUB["Text Encoder"]
      direction TB
      E2_1["Tokenization Layer<br/>WordPiece/BPE"]
      E2_2["Embedding Layer<br/>Token → Vector"]
      E2_3["Hidden Layer: 768 dims<br/>Contextual Embeddings"]
      E2_1 --> E2_2 --> E2_3
    end
    
    subgraph ENC3_SUB["Audio Encoder - Whisper ASR"]
      direction TB
      E3_1["Mel Spectrogram<br/>Audio → Frequency Features"]
      E3_2["Conv Layers x2<br/>Feature Extraction"]
      E3_3["Transformer Encoder<br/>Self-Attention Layers"]
      E3_4["Hidden Layer: 512 dims<br/>Audio Context Vector"]
      E3_5["Text Transcription Output"]
      E3_1 --> E3_2 --> E3_3 --> E3_4 --> E3_5
    end
  end

  BLOCK3 --> BLOCK4

  %% ========================================
  %% BLOCK 4: DECODER (compact in main flow; see separate diagram below)
  %% ========================================
  BLOCK4["BLOCK 4: DECODER<br/>Image / Text / Audio paths → Fusion<br/>Detail and formulas in diagram below"]

  BLOCK4 --> BLOCK5

  %% ========================================
  %% BLOCK 5: RAG + LLM NUTRITION ESTIMATION
  %% ========================================
  subgraph BLOCK5["BLOCK 5: NUTRITION ESTIMATION"]
    direction TB
    RAG["RAG System<br/>Vector Store: FAISS/Chroma<br/>Nutrition Database Retrieval"]
    LLM["Groq LLaMA-3 8B<br/>LLM Inference"]
    JSON["Nutrition JSON Output<br/>• Calories<br/>• Protein/Carbs/Fat<br/>• Micronutrients"]
    RAG --> LLM --> JSON
  end

  BLOCK5 --> BLOCK6

  %% ========================================
  %% BLOCK 6: STORAGE + TRACKING
  %% ========================================
  subgraph BLOCK6["BLOCK 6: STORAGE & TRACKING"]
    direction TB
    DB[("PostgreSQL Database<br/>• Food Logs<br/>• User Profiles<br/>• Daily Totals")]
    GOALS["User Goals Comparison<br/>• Calorie Targets<br/>• Macro Goals<br/>• Progress Tracking"]
    DB --> GOALS
  end

  BLOCK6 --> BLOCK7

  %% ========================================
  %% BLOCK 7: VISUALIZATION + ADVICE
  %% ========================================
  subgraph BLOCK7["BLOCK 7: VISUALIZATION & ADVICE"]
    direction TB
    VIZ["Data Visualization<br/>Matplotlib/Plotly<br/>• Calorie Charts<br/>• Macro Pie Charts"]
    ADVICE["AI Advice Engine<br/>LangChain + LLaMA<br/>• Gap Analysis<br/>• Personalized Suggestions"]
    VIZ -.-> ADVICE
  end

  BLOCK7 --> BLOCK8

  %% ========================================
  %% BLOCK 8: OUTPUT & DELIVERY
  %% ========================================
  subgraph BLOCK8["BLOCK 8: OUTPUT & DELIVERY"]
    direction TB
    PDF["PDF Report Generator<br/>FPDF/ReportLab<br/>• Food Logs<br/>• Charts<br/>• Advice"]
    DOWNLOAD["Download Options<br/>Save Locally<br/>Email<br/>Cloud Storage"]
    PDF --> DOWNLOAD
  end

  BLOCK8 --> END

  END(["END<br/>User Receives Report"])

  %% STYLING
  classDef inputStyle fill:#dbeafe,stroke:#3b82f6,stroke-width:2px,color:#1e3a8a
  classDef processStyle fill:#dcfce7,stroke:#22c55e,stroke-width:2px,color:#166534
  classDef encoderStyle fill:#fef3c7,stroke:#f59e0b,stroke-width:2px,color:#92400e
  classDef decoderStyle fill:#fed7aa,stroke:#ea580c,stroke-width:2px,color:#7c2d12
  classDef llmStyle fill:#e9d5ff,stroke:#a855f7,stroke-width:2px,color:#6b21a8
  classDef storageStyle fill:#e0e7ff,stroke:#6366f1,stroke-width:2px,color:#3730a3
  classDef vizStyle fill:#fce7f3,stroke:#ec4899,stroke-width:2px,color:#9f1239
  classDef outputStyle fill:#d1fae5,stroke:#10b981,stroke-width:2px,color:#065f46

  class BLOCK1 inputStyle
  class BLOCK2 processStyle
  class BLOCK3 encoderStyle
  class BLOCK4 decoderStyle
  class BLOCK5 llmStyle
  class BLOCK6 storageStyle
  class BLOCK7 vizStyle
  class BLOCK8 outputStyle
        </pre>
      </div>

      <div class="hint">
        <strong>Architecture Overview:</strong> This diagram shows the complete system divided into 8 functional blocks. 
        BLOCK 4 (Decoder) is expanded with formulas in the separate diagram below.
      </div>

      <h2 style="margin: 32px 0 12px; font-size: 18px; color: #111827;">BLOCK 4: DECODER — Formulas (all blocks)</h2>
      <p style="margin: 0 0 16px; color: var(--muted); font-size: 13px;">
        d=768, d_v, L_v, T, d_h. V∈ℝ^(L_v×d_v), H^(ℓ)∈ℝ^(T×d). ⊕ concat.
      </p>
      <div class="card">
        <pre class="mermaid">
flowchart TB
  subgraph S10["§10 Overall Decoder Mapping — Summary"]
    N10["Block: Overall Decoder Mapping<br/>c_img=Dec_img(V); c_txt=CleanText(x_txt); c_asr=ASR(a); P_total=Merge(c_img,c_txt,c_asr,c_user,c_hist)"]
  end

  subgraph S1_6["§1–§6 Image path — BLIP-2 GPT-2 Decoder"]
    N1["§1 Visual Feature Projection into GPT-2 Space<br/>H_v = V W_v + 1 b_v^⊤ ∈ ℝ^(L_v×d)"]
    N2["§2 Layer Normalization (throughout decoder)<br/>LN: γ·(x−μ)/√(σ²+ε)+β"]
    N3["§3 Cross-Attention Layer — Visual Features to Text<br/>Q,K,V from H_in,H_v; A=softmax(QK^⊤/√d_h); H_cross=LN(H_in+O)"]
    N4["§4 Transformer Decoder x12 — Causal Self-Attention<br/>M_ij=0 j≤i else −∞; H_self=LN(H_cross+O_self) ∈ ℝ^(T×768)"]
    N5["§5 Feed-Forward Network — 2048 to 768 dims<br/>u=hW_1+b_1, a=GELU(u), v=aW_2+b_2; d_ff=2048"]
    N6["§6 Output Layer — Vocabulary Projection and Caption Generation<br/>z_t=H_out(t)W^V+b^V; y_t=argmax_k softmax(z_t)_k → Food Description Text"]
    N1 --> N2 --> N3 --> N4 --> N5 --> N6
  end

  subgraph S7["§7 Text Path — Direct (Cleaned Text to Description)"]
    N7a["Block: Text Path Direct — Embedding<br/>e_t = E(w_t)+p_t"]
    N7b["Block: Text Path Direct — Pooled for fusion<br/>f_txt = (1/T_txt)∑e_t"]
    N7a --> N7b
  end

  subgraph S8["§8 Audio Path — ASR Output Frozen (Speech to Text to Description)"]
    N8a["Block: Audio Path — Mel and Encoder<br/>S=MelSpectrogram(a); h_enc=Encoder(S); p(y_t|y_&lt;t,h_enc)=softmax(g(·))"]
    N8b["Block: Audio Path — ASR transcript embedding<br/>e_t^asr=E(u_t)+p_t; f_asr=(1/T_asr)∑e_t^asr"]
    N8a --> N8b
  end

  subgraph S9["§9 Fusion Module — LangChain Prompt Manager, Context Fusion Layer"]
    N9["Block: Fusion — Confidence-Weight Combined Food Descripter<br/>P_total=IMG⊕c_img⊕TXT⊕c_txt⊕AUDIO⊕c_asr; f_fused=(w_img f_img+w_txt f_txt+w_asr f_asr)/(w_img+w_txt+w_asr)"]
  end

  N6 --> N9
  N7b --> N9
  N8b --> N9

  classDef decStyle fill:#fed7aa,stroke:#ea580c,stroke-width:2px,color:#7c2d12
  class S10,S1_6,S7,S8,S9 decStyle
        </pre>
      </div>
      <div class="hint">
        Block names: §1 Visual Feature Projection into GPT-2 Space · §2 Layer Normalization · §3 Cross-Attention Layer · §4 Transformer Decoder (Causal Self-Attention) · §5 Feed-Forward Network · §6 Output Layer (Vocabulary Projection and Caption Generation) · §7 Text Path Direct · §8 Audio Path ASR Output (Frozen) · §9 Fusion Module (LangChain Prompt Manager, Context Fusion Layer) · §10 Overall Decoder Mapping (Summary).
      </div>
    </div>

    <script type="module">
      import mermaid from "https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs";
      mermaid.initialize({
        startOnLoad: true,
        theme: "default",
        flowchart: { 
          curve: "linear",
          padding: 20
        },
        securityLevel: "loose",
      });
    </script>
  </body>
</html>


